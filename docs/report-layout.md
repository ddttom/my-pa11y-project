# Report Layout Reference for AI Assistants

This document provides a comprehensive technical reference for all report structures generated by the SEO Analysis Tool. Each section details the exact field names, data types, and relationships between reports.

**Purpose**: Enable AI assistants to accurately parse, analyze, and query report data without requiring human interpretation.

**Last Updated**: 2026-01-01
**Schema Version**: 2.0.0

---

## Report Overview

The tool generates **18+ reports** in CSV format (plus XML, Markdown, JSON, and HTML files):

| Report File | Primary Key | Record Type | Aggregation Level |
|-------------|-------------|-------------|-------------------|
| `seo_report.csv` | URL | Per-page | Page-level |
| `performance_analysis.csv` | URL | Per-page | Page-level |
| `accessibility_report.csv` | URL | Per-page | Page-level |
| `wcag_report.md` | URL | Per-page | Page-level |
| `content_quality.csv` | URL | Per-page | Page-level |
| `seo_scores.csv` | URL | Per-page | Page-level |
| `llm_readability_report.csv` | URL | Per-page | Page-level |
| `http_status_report.csv` | URL | Per-page | Page-level |
| `robots_txt_quality.csv` | URL | Per-file | File-level |
| `llms_txt_quality.csv` | URL | Per-file | File-level |
| `ai_files_summary.md` | - | Site-wide | Site-wide |
| `image_optimization.csv` | Page URL + Image URL | Per-image | Image-level |
| `link_analysis.csv` | Source URL + Target URL | Per-link | Link-level |
| `all_resources_report.csv` | Resource URL | Per-resource | Site-wide |
| `missing_sitemap_urls.csv` | Discovered URL | Per-URL | Site-wide |
| `v-sitemap.xml` | loc (URL) | Per-URL | Site-wide |
| `executive_summary.md` | - | Site-wide | Site-wide |
| `executive_summary.json` | - | Site-wide | Site-wide |
| `dashboard.html` | - | Site-wide | Site-wide |
| `history/results-*.json` | - | Site-wide | Historical |

### Enhanced Reports (Optional)

The following reports are generated when specific CLI flags are used:

- **Executive Summary** (`--generate-executive-summary`):
  - `executive_summary.md` - Human-readable executive summary
  - `executive_summary.json` - Machine-readable summary for automation

- **Interactive Dashboard** (`--generate-dashboard`):
  - `dashboard.html` - Self-contained HTML with embedded charts

- **Historical Data** (`--enable-history`):
  - `history/results-<timestamp>.json` - Timestamped complete results

---

## 1. SEO Report (`seo_report.csv`)

**Purpose**: Basic SEO metrics for each analyzed page
**Key Field**: `URL`
**Sort Order**: Unsorted (insertion order)

### Fields

| Field Name | Data Type | Description | Possible Values | Nullable |
|------------|-----------|-------------|-----------------|----------|
| `URL` | String (URL) | Fully qualified page URL | Valid HTTP/HTTPS URL | No |
| `Title` | String | Page `<title>` content | Any text, max ~60 chars recommended | Yes |
| `Description` | String | Meta description content | Any text, max ~160 chars recommended | Yes |
| `H1 Count` | Integer | Number of `<h1>` elements | 0 to N (1 recommended) | No |
| `Image Count` | Integer | Total `<img>` elements | 0 to N | No |
| `Images Without Alt` | Integer | Images missing alt attribute | 0 to `Image Count` | No |
| `Internal Links` | Integer | Same-domain links | 0 to N | No |
| `External Links` | Integer | Cross-domain links | 0 to N | No |
| `Page Size` | Integer | HTML size in bytes | Positive integer | No |
| `Word Count` | Integer | Text word count | 0 to N | No |
| `Title Length` | Integer | Title string length | 0 to N (50-60 recommended) | No |
| `Description Length` | Integer | Description string length | 0 to N (150-160 recommended) | No |
| `Has Structured Data` | Boolean | Presence of JSON-LD/Microdata | `true`, `false` | No |
| `Has Social Tags` | Boolean | Presence of OpenGraph/Twitter tags | `true`, `false` | No |
| `Last Modified` | ISO 8601 DateTime | Last-Modified header or meta tag | `YYYY-MM-DDTHH:mm:ss.sssZ` | Yes |

### Example Row

```csv
URL,Title,Description,H1 Count,Image Count,Images Without Alt,Internal Links,External Links,Page Size,Word Count,Title Length,Description Length,Has Structured Data,Has Social Tags,Last Modified
https://example.com/page,"Example Page Title","This is a meta description",1,5,2,12,3,45678,523,18,26,true,true,2025-12-01T10:30:00.000Z
```

---

## 2. Performance Analysis (`performance_analysis.csv`)

**Purpose**: Page load and Core Web Vitals metrics
**Key Field**: `URL`
**Sort Order**: Unsorted (insertion order)

### Fields

| Field Name | Data Type | Unit | Description | Threshold (Good) | Nullable |
|------------|-----------|------|-------------|------------------|----------|
| `URL` | String (URL) | - | Fully qualified page URL | - | No |
| `Load Time (ms)` | Integer | Milliseconds | Total page load time | < 2000ms | No |
| `First Paint (ms)` | Integer | Milliseconds | Time to first pixel painted | < 1000ms | Yes |
| `First Contentful Paint (ms)` | Integer | Milliseconds | Time to first content painted (FCP) | < 1800ms | Yes |
| `Largest Contentful Paint (ms)` | Integer | Milliseconds | Time to largest content element (LCP) | < 2500ms | Yes |
| `Time to Interactive (ms)` | Integer | Milliseconds | Time until page fully interactive (TTI) | < 3800ms | Yes |
| `Total Blocking Time (ms)` | Integer | Milliseconds | Sum of blocking time (TBT) | < 200ms | Yes |
| `Cumulative Layout Shift` | Float | Score | Visual stability metric (CLS) | < 0.1 | Yes |

### Core Web Vitals Summary

- **LCP (Largest Contentful Paint)**: Good < 2.5s, Needs Improvement 2.5-4s, Poor > 4s
- **FID (First Input Delay)**: Good < 100ms, Needs Improvement 100-300ms, Poor > 300ms (not directly measured, TTI used as proxy)
- **CLS (Cumulative Layout Shift)**: Good < 0.1, Needs Improvement 0.1-0.25, Poor > 0.25

### Example Row

```csv
URL,Load Time (ms),First Paint (ms),First Contentful Paint (ms),Largest Contentful Paint (ms),Time to Interactive (ms),Total Blocking Time (ms),Cumulative Layout Shift
https://example.com/page,1523,345,456,1234,2345,123,0.05
```

---

## 3. Accessibility Report (`accessibility_report.csv`)

**Purpose**: WCAG 2.1 compliance analysis with Pa11y integration
**Key Field**: `URL`
**Sort Order**: Unsorted (insertion order)

### Fields

| Field Name | Data Type | Description | Calculation | Nullable |
|------------|-----------|-------------|-------------|----------|
| `URL` | String (URL) | Fully qualified page URL | - | No |
| `Total Issues` | Integer | Sum of all accessibility issues | Critical + Serious + Moderate + Minor | No |
| `Critical Issues` | Integer | Issues preventing access | Pa11y error level | No |
| `Serious Issues` | Integer | Major barriers to access | Pa11y error level | No |
| `Moderate Issues` | Integer | Noticeable barriers | Pa11y warning level | No |
| `Minor Issues` | Integer | Small improvements needed | Pa11y notice level | No |
| `WCAG A Issues` | Integer | Level A violations | Pa11y WCAG 2.1 A | No |
| `WCAG AA Issues` | Integer | Level AA violations | Pa11y WCAG 2.1 AA | No |
| `WCAG AAA Issues` | Integer | Level AAA violations | Pa11y WCAG 2.1 AAA | No |
| `WCAG 2.1 Compliance Percentage` | Float | Percentage of passed checks | (Total checks - Issues) / Total checks × 100 | No |
| `Missing ARIA Labels` | Integer | Elements missing ARIA labels | Pa11y detection | No |
| `Contrast Ratio Issues` | Integer | Color contrast failures | WCAG contrast requirements | No |
| `Keyboard Navigation Issues` | Integer | Keyboard accessibility problems | Pa11y detection | No |
| `Required Manual Checks` | Integer | Issues requiring human review | Pa11y manual check flags | No |
| `Remediation Suggestions` | String | Comma-separated fix suggestions | Generated from issue types | Yes |

### Severity Level Mapping

- **Critical**: Completely blocks access for users with disabilities
- **Serious**: Major barriers, significantly impairs access
- **Moderate**: Noticeable problems, may require workarounds
- **Minor**: Minor improvements, best practice violations

### Example Row

```csv
URL,Total Issues,Critical Issues,Serious Issues,Moderate Issues,Minor Issues,WCAG A Issues,WCAG AA Issues,WCAG AAA Issues,WCAG 2.1 Compliance Percentage,Missing ARIA Labels,Contrast Ratio Issues,Keyboard Navigation Issues,Required Manual Checks,Remediation Suggestions
https://example.com/page,12,2,3,5,2,3,4,5,85.5,3,2,1,4,"Add alt text to images,Improve color contrast,Add ARIA labels"
```

---

## 4. WCAG Markdown Report (`wcag_report.md`)

**Purpose**: Human-readable accessibility report with detailed issue descriptions
**Format**: Markdown
**Structure**: Hierarchical by URL

### Structure

```markdown
# WCAG 2.1 Accessibility Report

## Summary Statistics
- Total Pages Analyzed: N
- Total Issues Found: N
- Pages with Critical Issues: N
- Average Compliance: N%

## Issues by URL

### https://example.com/page1

#### Issue: [WCAG Guideline Code] Issue Title
- **Severity**: Critical/Serious/Moderate/Minor
- **WCAG Level**: A/AA/AAA
- **Occurrences**: N
- **Description**: Detailed description of the issue
- **Remediation**: How to fix the issue
- **Selector**: CSS selector where issue occurs
- **Context**: HTML snippet showing the problem

---
```

### Field Descriptions

| Section | Content Type | Description |
|---------|--------------|-------------|
| Summary Statistics | Aggregated metrics | Site-wide totals and averages |
| Issue Title | String | Pa11y issue code and human-readable title |
| Severity | Enum | `Critical`, `Serious`, `Moderate`, `Minor` |
| WCAG Level | Enum | `A`, `AA`, `AAA` |
| Occurrences | Integer | Number of times this exact issue appears on the page |
| Description | String | Detailed explanation of the accessibility problem |
| Remediation | String | Step-by-step fix instructions |
| Selector | String | CSS selector identifying the problematic element |
| Context | HTML | Code snippet showing the issue in context |

---

## 5. Content Quality (`content_quality.csv`)

**Purpose**: Content analysis and quality scoring
**Key Field**: `URL`
**Sort Order**: Unsorted (insertion order)

### Fields

| Field Name | Data Type | Range | Description | Good Threshold | Nullable |
|------------|-----------|-------|-------------|----------------|----------|
| `URL` | String (URL) | - | Fully qualified page URL | - | No |
| `Word Count` | Integer | 0 to N | Total words in main content | > 300 | No |
| `Content Freshness Score` | Float | 0-100 | Recency of content updates | > 70 | No |
| `Content Uniqueness Score` | Float | 0-100 | Estimated originality | > 80 | No |
| `Grammar Score` | Float | 0-100 | Basic grammar quality | > 85 | No |
| `Media Richness Score` | Float | 0-100 | Multimedia content presence | > 60 | No |
| `Top Keywords` | String | - | Comma-separated top 10 keywords | - | Yes |
| `Overall Content Score` | Float | 0-100 | Weighted average of all scores | > 75 | No |

### Score Calculation Details

- **Content Freshness Score**: Based on Last-Modified date, decays over time
- **Content Uniqueness Score**: Simple heuristic based on content patterns (not true duplicate detection)
- **Grammar Score**: Basic checks for sentence structure, punctuation
- **Media Richness Score**: (Images + Videos + Audio) presence and quality
- **Overall Content Score**: Weighted average: (Word Count×0.2 + Freshness×0.2 + Uniqueness×0.25 + Grammar×0.15 + Media×0.2)

### Example Row

```csv
URL,Word Count,Content Freshness Score,Content Uniqueness Score,Grammar Score,Media Richness Score,Top Keywords,Overall Content Score
https://example.com/page,523,85.5,92.3,88.7,75.2,"keyword1,keyword2,keyword3,keyword4,keyword5",84.6
```

---

## 6. SEO Scores (`seo_scores.csv`)

**Purpose**: Comprehensive SEO scoring with component breakdown
**Key Field**: `URL`
**Sort Order**: By score (descending)

### Fields

| Field Name | Data Type | Range | Weight | Description | Nullable |
|------------|-----------|-------|--------|-------------|----------|
| `URL` | String (URL) | - | - | Fully qualified page URL | No |
| `Overall Score` | Float | 0-100 | - | Weighted sum of all component scores | No |
| `Title Score` | Float | 0-100 | 15% | Title tag quality (length, keywords) | No |
| `Meta Description Score` | Float | 0-100 | 10% | Meta description quality | No |
| `Heading Structure Score` | Float | 0-100 | 15% | H1-H6 hierarchy and usage | No |
| `Content Score` | Float | 0-100 | 20% | Content quality and length | No |
| `Image Optimization Score` | Float | 0-100 | 10% | Alt text and image best practices | No |
| `Internal Linking Score` | Float | 0-100 | 10% | Internal link presence and quality | No |
| `Mobile Friendliness Score` | Float | 0-100 | 5% | Mobile optimization indicators | No |
| `Performance Score` | Float | 0-100 | 10% | Page speed and Core Web Vitals | No |
| `Structured Data Score` | Float | 0-100 | 5% | Schema.org markup presence | No |

### Score Thresholds

- **Excellent**: 90-100
- **Good**: 70-89
- **Fair**: 50-69
- **Poor**: 0-49

### Overall Score Calculation

```
Overall Score = (Title×0.15) + (MetaDesc×0.10) + (Headings×0.15) + (Content×0.20) +
                (Images×0.10) + (InternalLinks×0.10) + (Mobile×0.05) +
                (Performance×0.10) + (StructuredData×0.05)
```

### Example Row

```csv
URL,Overall Score,Title Score,Meta Description Score,Heading Structure Score,Content Score,Image Optimization Score,Internal Linking Score,Mobile Friendliness Score,Performance Score,Structured Data Score
https://example.com/page,82.5,90,85,80,75,88,70,95,85,100
```

---

## 7. LLM Readability Report (`llm_readability_report.csv`)

**Purpose**: Evaluate how well page structure supports LLM content extraction
**Key Field**: `URL`
**Sort Order**: By Overall Score (descending)

### Fields

| Field Name | Data Type | Range | Weight | Description | Nullable |
|------------|-----------|-------|--------|-------------|----------|
| `URL` | String (URL) | - | - | Fully qualified page URL | No |
| `Overall LLM Readability Score` | Float | 0-100 | - | Weighted average of component scores | No |
| `Structural Clarity Score` | Float | 0-100 | 30% | Semantic HTML usage quality | No |
| `Content Organization Score` | Float | 0-100 | 30% | Content structure and hierarchy | No |
| `Metadata Quality Score` | Float | 0-100 | 20% | Structured data and meta tags | No |
| `Text Extractability Score` | Float | 0-100 | 20% | Ease of text content extraction | No |
| `Semantic HTML Usage` | Float | 0-100% | - | Percentage of semantic elements used | No |
| `Heading Hierarchy Quality` | Float | 0-100 | - | H1-H6 logical structure score | No |
| `Has Main Content` | Boolean | - | - | Presence of `<main>` or `role="main"` | No |
| `Has Structured Data` | Boolean | - | - | JSON-LD or Microdata present | No |
| `Text to Markup Ratio` | Float | 0-1.0 | - | Text content / Total markup size | No |
| `Hidden Content Ratio` | Float | 0-100% | - | Percentage of visually hidden elements | No |
| `Paragraph Count` | Integer | 0-N | - | Number of `<p>` elements | No |
| `List Count` | Integer | 0-N | - | Number of `<ul>` and `<ol>` elements | No |
| `Table Count` | Integer | 0-N | - | Number of `<table>` elements | No |
| `Code Block Count` | Integer | 0-N | - | Number of `<pre>` and `<code>` elements | No |
| `Total Elements` | Integer | 0-N | - | Total DOM element count | No |

### Component Score Calculations

**Structural Clarity Score**:

```
Score = (Semantic Elements / Total Elements × 40) +
        (Heading Hierarchy Quality × 30) +
        (Has Main Content × 30)
```

**Content Organization Score**:

```
Score = (Paragraph Count > 3 × 30) +
        (List Count > 0 × 20) +
        (Table Count appropriate × 20) +
        (Content Length appropriate × 30)
```

**Metadata Quality Score**:

```
Score = (Has Structured Data × 50) +
        (OpenGraph Tags Quality × 30) +
        (Meta Description Quality × 20)
```

**Text Extractability Score**:

```
Score = (Text to Markup Ratio × 60) +
        ((1 - Hidden Content Ratio) × 40)
```

### Score Interpretation

| Range | Interpretation | Recommendation |
|-------|---------------|----------------|
| 90-100 | Excellent | Optimal for LLM extraction |
| 70-89 | Good | Minor improvements possible |
| 50-69 | Moderate | Significant improvements recommended |
| 0-49 | Poor | Major structural improvements needed |

### Example Row

```csv
URL,Overall LLM Readability Score,Structural Clarity Score,Content Organization Score,Metadata Quality Score,Text Extractability Score,Semantic HTML Usage,Heading Hierarchy Quality,Has Main Content,Has Structured Data,Text to Markup Ratio,Hidden Content Ratio,Paragraph Count,List Count,Table Count,Code Block Count,Total Elements
https://example.com/page,85.5,90.0,82.5,88.0,81.0,75.5,85,true,true,0.45,5.2,25,8,3,2,487
```

---

## 8. HTTP Status Report (`http_status_report.csv`)

**Purpose**: Track all non-200 HTTP responses (redirects, errors, etc.)
**Key Field**: `URL`
**Sort Order**: By Status Code (descending)

### Fields

| Field Name | Data Type | Description | Possible Values | Nullable |
|------------|-----------|-------------|-----------------|----------|
| `URL` | String (URL) | Fully qualified page URL | Valid HTTP/HTTPS URL | No |
| `Status Code` | Integer | HTTP response status code | 301, 302, 307, 308, 400, 401, 403, 404, 500, 502, 503, etc. | No |
| `Status Text` | String | Human-readable status description | "Moved Permanently", "Not Found", etc. | No |
| `Timestamp` | ISO 8601 DateTime | When the status was recorded | `YYYY-MM-DDTHH:mm:ss.sssZ` | No |

### Common Status Codes

| Code | Status Text | Category | Description |
|------|-------------|----------|-------------|
| 301 | Moved Permanently | Redirect | Permanent redirect to new location |
| 302 | Found (Temporary Redirect) | Redirect | Temporary redirect |
| 307 | Temporary Redirect | Redirect | Temporary redirect preserving method |
| 308 | Permanent Redirect | Redirect | Permanent redirect preserving method |
| 400 | Bad Request | Client Error | Malformed request syntax |
| 401 | Unauthorized | Client Error | Authentication required |
| 403 | Forbidden | Client Error | No permission to access resource |
| 404 | Not Found | Client Error | Resource does not exist |
| 410 | Gone | Client Error | Resource permanently removed |
| 429 | Too Many Requests | Client Error | Rate limit exceeded |
| 500 | Internal Server Error | Server Error | Generic server error |
| 502 | Bad Gateway | Server Error | Invalid upstream response |
| 503 | Service Unavailable | Server Error | Server temporarily unavailable |
| 504 | Gateway Timeout | Server Error | Upstream server timeout |

### Example Rows

```csv
URL,Status Code,Status Text,Timestamp
https://example.com/old-page,301,Moved Permanently,2025-12-07T10:30:45.123Z
https://example.com/missing,404,Not Found,2025-12-07T10:31:12.456Z
https://example.com/error,500,Internal Server Error,2025-12-07T10:32:03.789Z
```

---

## 9. robots.txt Quality Report (`robots_txt_quality.csv`)

**Purpose**: Analyze robots.txt file quality for AI agent compatibility
**Key Field**: `URL`
**Sort Order**: Unsorted (typically one file per site)
**Reference**: Based on guidance from "The Invisible Users" book

### Fields

| Field Name | Data Type | Description | Possible Values | Nullable |
|------------|-----------|-------------|-----------------|----------|
| `URL` | String (URL) | URL to robots.txt file | `https://example.com/robots.txt` | No |
| `File Exists` | Boolean | Whether file is accessible | `true`, `false` | No |
| `Overall Quality` | String (Enum) | Quality assessment | `Excellent`, `Good`, `Fair`, `Poor`, `Missing` | No |
| `Quality Score` | Integer | Numeric quality score | 0-100 | No |
| `Max Score` | Integer | Maximum possible score | 100 | No |
| `Has AI User Agents` | Boolean | Declares AI-specific user agents | `true`, `false` | No |
| `AI User Agents Found` | String | Semicolon-separated list | `GPTBot; ClaudeBot; PerplexityBot` | Yes |
| `Has Sitemap` | Boolean | Contains sitemap reference | `true`, `false` | No |
| `Sitemap Count` | Integer | Number of sitemaps declared | 0 to N | No |
| `Protects Sensitive Paths` | Boolean | Disallows sensitive directories | `true`, `false` | No |
| `Protected Paths` | String | Semicolon-separated list | `/admin; /account; /cart` | Yes |
| `References llms.txt` | Boolean | Comments mention llms.txt | `true`, `false` | No |
| `Has Comments` | Boolean | Contains explanatory comments | `true`, `false` | No |
| `Total Rules` | Integer | Number of allow/disallow rules | 0 to N | No |
| `Structure Quality` | String (Enum) | Structure assessment | `Excellent`, `Good`, `Basic`, `Unknown` | No |
| `Issues` | String | Semicolon-separated issues | `No AI-specific user agents found` | Yes |
| `Recommendations` | String | Semicolon-separated recommendations | `Add GPTBot, ClaudeBot declarations` | Yes |

### Quality Scoring Breakdown

**Total Score: 100 points**

- **AI User Agents (30 points)**
  - 30 points: 3+ AI user agents declared
  - 20 points: 1-2 AI user agents declared
  - 5 points: Generic user agents only

- **Sitemap References (20 points)**
  - 20 points: At least one sitemap declared
  - 0 points: No sitemaps

- **Sensitive Path Protection (25 points)**
  - 25 points: 3+ sensitive paths protected
  - 15 points: 1-2 sensitive paths protected
  - 0 points: No protection

- **llms.txt Reference (15 points)**
  - 15 points: Comments mention llms.txt
  - 0 points: No reference

- **Comments and Documentation (10 points)**
  - 10 points: 3+ helpful comments
  - 5 points: 1-2 comments
  - 0 points: No comments

- **Completeness Bonus (10 points)**
  - 10 points: All elements present

### Example Row

```csv
URL,File Exists,Overall Quality,Quality Score,Max Score,Has AI User Agents,AI User Agents Found,Has Sitemap,Sitemap Count,Protects Sensitive Paths,Protected Paths,References llms.txt,Has Comments,Total Rules,Structure Quality,Issues,Recommendations
https://example.com/robots.txt,true,Good,75,100,true,GPTBot; ClaudeBot,true,1,true,/admin; /account; /cart,false,true,12,Good,,"Add llms.txt reference in comments"
```

---

## 10. llms.txt Quality Report (`llms_txt_quality.csv`)

**Purpose**: Evaluate llms.txt file quality for AI agent guidance
**Key Field**: `URL`
**Sort Order**: Unsorted (typically one file per site)
**Reference**: Based on llmstxt.org specification and "The Invisible Users" book

### Fields

| Field Name | Data Type | Description | Possible Values | Nullable |
|------------|-----------|-------------|-----------------|----------|
| `URL` | String (URL) | URL to llms.txt file | `https://example.com/llms.txt` | No |
| `File Exists` | Boolean | Whether file is accessible | `true`, `false` | No |
| `Overall Quality` | String (Enum) | Quality assessment | `Excellent`, `Good`, `Fair`, `Poor`, `Very Poor`, `Missing` | No |
| `Quality Score` | Integer | Numeric quality score | 0-100 | No |
| `Max Score` | Integer | Maximum possible score | 100 | No |
| `Has Title` | Boolean | Contains H1 title | `true`, `false` | No |
| `Title` | String | Extracted H1 title | Any text | Yes |
| `Has Description` | Boolean | Contains site description | `true`, `false` | No |
| `Has Contact` | Boolean | Contains contact information | `true`, `false` | No |
| `Contact` | String | Contact email or URL | Any text | Yes |
| `Has Last Updated` | Boolean | Contains last updated date | `true`, `false` | No |
| `Last Updated` | String | Last updated timestamp | Date string | Yes |
| `Has Site Type` | Boolean | Declares site type | `true`, `false` | No |
| `Site Type` | String | Site category | `E-Commerce`, `Content-Driven`, `API-Driven`, etc. | Yes |
| `Core Elements Present` | Integer | Number of core elements | 0-4 | No |
| `Core Elements Total` | Integer | Total core elements expected | 4 | No |
| `Sections Present` | Integer | Number of important sections | 0-6 | No |
| `Sections Total` | Integer | Total sections recommended | 6 | No |
| `Word Count` | Integer | Total words in file | 0 to N | No |
| `Line Count` | Integer | Total lines in file | 0 to N | No |
| `Link Count` | Integer | Number of documentation links | 0 to N | No |
| `Heading Count` | Integer | Number of markdown headings | 0 to N | No |
| `Content Length Assessment` | String (Enum) | Content adequacy | `Comprehensive`, `Adequate`, `Minimal`, `Insufficient`, `Unknown` | No |
| `Specificity Level` | String (Enum) | Detail level | `High`, `Medium`, `Low`, `Unknown` | No |
| `Has Structured Content` | Boolean | Well-organized sections | `true`, `false` | No |
| `Issues` | String | Semicolon-separated issues | `Missing contact information` | Yes |
| `Recommendations` | String | Semicolon-separated recommendations | `Add API documentation section` | Yes |

### Core Elements

Required elements for a quality llms.txt file:

1. **Title (H1)** - Site identification
2. **Description** - Purpose and content type
3. **Contact** - Email for AI policy questions
4. **Last Updated** - Version timestamp

### Important Sections

Recommended sections for comprehensive guidance:

1. **Access Guidelines** - Rate limits, usage policies
2. **Content Restrictions** - Off-limits paths and data
3. **API Access** - Endpoints, authentication
4. **Training Guidelines** - Permitted/prohibited uses
5. **Attribution** - How to credit content
6. **Error Handling** - Retry logic, fallbacks

### Quality Scoring Breakdown

**Total Score: 105 points (bonus possible)**

- **Core Elements (40 points)** - 10 points each
  - Title, Description, Contact, Last Updated

- **Important Sections (30 points)** - 5 points each
  - Access Guidelines, Content Restrictions, API Access, Training Guidelines, Attribution, Error Handling

- **Content Structure and Length (15 points)**
  - 15 points: 200+ words (Comprehensive)
  - 10 points: 100-199 words (Adequate)
  - 5 points: 50-99 words (Minimal)
  - 0 points: <50 words (Insufficient)

- **Links and Documentation (10 points)**
  - 10 points: 5+ links
  - 7 points: 3-4 links
  - 4 points: 1-2 links
  - 0 points: No links

- **Specificity and Detail (5 points)**
  - Checks for rate limits, API endpoints, specific paths

- **Bonus Points (up to 5 points)**
  - Site type declared (+3)
  - 5+ headings (+2)

### Example Row

```csv
URL,File Exists,Overall Quality,Quality Score,Max Score,Has Title,Title,Has Description,Has Contact,Contact,Has Last Updated,Last Updated,Has Site Type,Site Type,Core Elements Present,Core Elements Total,Sections Present,Sections Total,Word Count,Line Count,Link Count,Heading Count,Content Length Assessment,Specificity Level,Has Structured Content,Issues,Recommendations
https://example.com/llms.txt,true,Good,78,100,true,Example Site,true,true,ai@example.com,true,2026-01-03,true,Content-Driven,4,4,4,6,245,58,6,8,Comprehensive,High,true,,"Add training guidelines section; Include specific rate limits"
```

---

## 11. AI Files Summary Report (`ai_files_summary.md`)

**Purpose**: Human-readable summary of robots.txt and llms.txt quality
**Format**: Markdown
**Aggregation Level**: Site-wide

### Structure

```markdown
# AI Files Quality Summary

**Generated**: [ISO timestamp]

## Overview

Summary of robots.txt and llms.txt quality for AI agent compatibility.

---

## robots.txt Analysis

**URL**: [robots.txt URL]
**Exists**: Yes/No
**Quality Score**: X/100 - Quality Level

### Quality Breakdown
- AI User Agents Declared: Yes/No (List)
- Sitemap Reference: Yes/No (Count)
- Sensitive Path Protection: Yes/No (Paths)
- References llms.txt: Yes/No
- Has Comments: Yes/No
- Total Rules: N
- Structure Quality: Level

### Issues
- [List of issues]

### Recommendations
- [List of recommendations]

---

## llms.txt Analysis

**URL**: [llms.txt URL]
**Exists**: Yes/No
**Quality Score**: X/100 - Quality Level

### File Contents
- Title: [Title]
- Description: [Description]
- Contact: [Contact]
- Last Updated: [Date]
- Site Type: [Type]

### Quality Metrics
- Core Elements: X/4 present
- Sections: X/6 present
- Content Length: Assessment (N words)
- Specificity: Level
- Links: N documentation links
- Headings: N sections

### Issues
- [List of issues]

### Recommendations
- [List of recommendations]

---

## Additional Resources

- llms.txt Specification: https://llmstxt.org/
- The Invisible Users Book: https://github.com/tomcranstoun/invisible-users
- robots.txt Standard: https://www.robotstxt.org/
```

### Key Sections

| Section | Content Type | Description |
|---------|--------------|-------------|
| Overview | Site-wide summary | Introduction and context |
| robots.txt Analysis | File quality | Detailed robots.txt assessment |
| llms.txt Analysis | File quality | Detailed llms.txt assessment |
| Quality Breakdown | Metrics | Specific quality indicators |
| Issues | Problems | Items requiring attention |
| Recommendations | Actions | Prioritized improvements |
| Additional Resources | Links | Reference documentation |

---

## 12. Image Optimization (`image_optimization.csv`)

**Purpose**: Per-image analysis and optimization recommendations
**Key Fields**: `Page URL` + `Image URL` (composite key)
**Sort Order**: By Optimization Score (ascending, worst first)

### Fields

| Field Name | Data Type | Description | Possible Values | Nullable |
|------------|-----------|-------------|-----------------|----------|
| `Page URL` | String (URL) | URL of page containing the image | Valid HTTP/HTTPS URL | No |
| `Image URL` | String (URL) | Direct URL to image resource | Valid HTTP/HTTPS URL | No |
| `File Size (KB)` | Float | Image file size in kilobytes | Positive float | Yes |
| `Dimensions` | String | Width × Height in pixels | "1920x1080", "800x600", etc. | Yes |
| `Format` | String | Image file format | "jpg", "png", "gif", "svg", "webp", etc. | Yes |
| `Alt Text` | String | Alt attribute content | Any text | Yes |
| `Alt Text Quality Score` | Float | Quality of alt text (0-100) | 0-100 | No |
| `Is Responsive` | Boolean | Has responsive sizing | `true`, `false` | No |
| `Lazy Loaded` | Boolean | Uses lazy loading | `true`, `false` | No |
| `Compression Level` | String | Estimated compression quality | "Low", "Medium", "High", "Unknown" | No |
| `Optimization Score` | Float | Overall optimization score (0-100) | 0-100 | No |
| `Recommendations` | String | Comma-separated improvement suggestions | "Add alt text", "Enable lazy loading", etc. | Yes |

### Alt Text Quality Scoring

| Score Range | Quality | Criteria |
|-------------|---------|----------|
| 90-100 | Excellent | 10-125 chars, descriptive, no "image of" prefix |
| 70-89 | Good | 5-150 chars, somewhat descriptive |
| 50-69 | Fair | 1-200 chars, generic or too long |
| 0-49 | Poor | Empty, "<1 char", or ">200 chars" |

### Optimization Score Calculation

```
Score = (Alt Text Quality × 0.25) +
        (File Size Appropriate × 0.25) +
        (Format Modern × 0.20) +
        (Is Responsive × 0.15) +
        (Lazy Loaded × 0.15)
```

### Example Row

```csv
Page URL,Image URL,File Size (KB),Dimensions,Format,Alt Text,Alt Text Quality Score,Is Responsive,Lazy Loaded,Compression Level,Optimization Score,Recommendations
https://example.com/page,https://example.com/img/photo.jpg,245.6,1920x1080,jpg,"A person using a laptop",85,true,true,Medium,78.5,"Consider WebP format,Reduce file size"
```

---

## 10. Link Analysis (`link_analysis.csv`)

**Purpose**: Per-link relationship and quality analysis
**Key Fields**: `Source URL` + `Target URL` (composite key)
**Sort Order**: Unsorted (insertion order)

### Fields

| Field Name | Data Type | Description | Possible Values | Nullable |
|------------|-----------|-------------|-----------------|----------|
| `Source URL` | String (URL) | Page containing the link | Valid HTTP/HTTPS URL | No |
| `Target URL` | String (URL) | Link destination | Valid HTTP/HTTPS URL | No |
| `Link Text` | String | Anchor text content | Any text | Yes |
| `Link Type` | String | Internal vs. external | "internal", "external" | No |
| `Follow Type` | String | SEO follow status | "follow", "nofollow" | No |
| `HTTP Status` | Integer | Target URL response code | 200, 301, 404, etc. | Yes |
| `Redirect Chain` | String | Redirect path if applicable | "301 → 302 → 200" | Yes |
| `Content Type` | String | MIME type of target | "text/html", "application/pdf", etc. | Yes |
| `In Navigation` | Boolean | Link is in navigation menu | `true`, `false` | No |
| `Link Depth` | Integer | Clicks from homepage | 0 to N | No |
| `Link Quality Score` | Float | Overall link quality (0-100) | 0-100 | No |

### Link Type Classification

- **Internal**: Same hostname as source page
- **External**: Different hostname from source page

### Link Quality Score Calculation

```
Score = (Has Link Text × 20) +
        (HTTP Status 200 × 30) +
        (No Redirect Chain × 20) +
        (Link Text Quality × 20) +
        (Link Depth Reasonable × 10)
```

### Example Row

```csv
Source URL,Target URL,Link Text,Link Type,Follow Type,HTTP Status,Redirect Chain,Content Type,In Navigation,Link Depth,Link Quality Score
https://example.com/page,https://example.com/about,About Us,internal,follow,200,,text/html,true,1,95.0
```

---

## 11. All Resources Report (`all_resources_report.csv`)

**Purpose**: Site-wide inventory of ALL resources (internal + external)
**Key Field**: `Resource URL`
**Sort Order**: By Total Count (descending, most-used first)

### Fields

| Field Name | Data Type | Description | Possible Values | Nullable |
|------------|-----------|-------------|-----------------|----------|
| `Resource URL` | String (URL) | Direct URL to resource | Valid HTTP/HTTPS URL | No |
| `Resource Type` | String (Enum) | Category of resource | See Resource Types below | No |
| `Total Count` | Integer | Number of pages using this resource | 1 to N | No |

### Resource Types

| Type | Description | Examples |
|------|-------------|----------|
| `javascript` | JavaScript files | `.js`, `<script src="">` |
| `css` | Stylesheets | `.css`, `<link rel="stylesheet">` |
| `image` | Image files | `.jpg`, `.png`, `.gif`, `.svg`, `.webp`, `<img src="">` |
| `font` | Web fonts | `.woff`, `.woff2`, `.ttf`, `@font-face` |
| `video` | Video files | `.mp4`, `.webm`, `<video src="">` |
| `audio` | Audio files | `.mp3`, `.wav`, `<audio src="">` |
| `iframe` | Embedded frames | `<iframe src="">` |
| `other` | Other resource types | `.json`, `.xml`, etc. |

### Domain Classification

Resources from ANY domain are included:

- Same-domain resources (e.g., `https://example.com/style.css`)
- External CDN resources (e.g., `https://cdn.example.com/jquery.js`)
- Third-party resources (e.g., `https://fonts.googleapis.com/font.woff2`)

### Use Cases

- Identify most-used resources across site
- Find critical dependencies (high count resources)
- Detect potential single points of failure
- Track external dependencies and CDN usage
- Analyze resource loading patterns

### Example Rows

```csv
Resource URL,Resource Type,Total Count
https://cdn.example.com/jquery-3.6.0.min.js,javascript,145
https://example.com/styles/main.css,css,138
https://fonts.googleapis.com/css2?family=Roboto,css,120
https://example.com/images/logo.png,image,98
https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/webfonts/fa-solid-900.woff2,font,87
```

---

## 12. Missing Sitemap URLs (`missing_sitemap_urls.csv`)

**Purpose**: Identify discovered URLs not in original sitemap
**Key Field**: `Discovered URL`
**Sort Order**: By Reference Count (descending, most-referenced first)

### Fields

| Field Name | Data Type | Description | Calculation | Nullable |
|------------|-----------|-------------|-------------|----------|
| `Discovered URL` | String (URL) | URL found during crawling | Same-domain URLs not in sitemap | No |
| `Reference Count` | Integer | Number of pages linking to this URL | Count of inbound links | No |
| `First Discovered On` | String (URL) | Source page that first linked to this URL | First encountered source | No |

### Discovery Process

1. Tool starts with original sitemap URLs
2. Extracts all same-domain links from each page
3. Compares discovered URLs against original sitemap
4. Reports URLs that are:
   - Same domain as analyzed site
   - NOT in original sitemap
   - Successfully crawled (not 404)

### Use Cases

- **SEO Improvement**: Add missing URLs to sitemap for better search engine coverage
- **Site Architecture**: Identify orphaned or unlisted pages
- **Content Audit**: Find pages that should be indexed but aren't in sitemap
- **Quality Control**: Detect pages accidentally excluded from sitemap

### Example Rows

```csv
Discovered URL,Reference Count,First Discovered On
https://example.com/blog/hidden-post,15,https://example.com/blog/archive
https://example.com/products/unlisted-item,8,https://example.com/search?q=item
https://example.com/about/team/member-5,5,https://example.com/about/team
```

---

## 13. Perfected Sitemap (`v-sitemap.xml`)

**Purpose**: XML sitemap combining original + discovered URLs
**Format**: XML (Sitemap Protocol)
**Sort Order**: Original URLs first, then discovered URLs

### Structure

```xml
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">

  <!-- Original sitemap URLs (no comment) -->
  <url>
    <loc>https://example.com/page1</loc>
    <lastmod>2025-12-01T10:00:00+00:00</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.8</priority>
  </url>

  <!-- Discovered URLs (marked with comment) -->
  <!-- Discovered during analysis -->
  <url>
    <loc>https://example.com/discovered-page</loc>
    <lastmod>2025-12-07T10:30:00+00:00</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.5</priority>
  </url>

</urlset>
```

### Elements

| Element | Required | Description | Example |
|---------|----------|-------------|---------|
| `<loc>` | Yes | Fully qualified URL | `https://example.com/page` |
| `<lastmod>` | No | Last modification date | `2025-12-07T10:30:00+00:00` |
| `<changefreq>` | No | Expected update frequency | `daily`, `weekly`, `monthly`, `yearly` |
| `<priority>` | No | Relative priority (0.0-1.0) | `0.8` for original, `0.5` for discovered |

### Discovered URL Marking

Discovered URLs are preceded by XML comment: `<!-- Discovered during analysis -->`

This allows:

- Visual identification in XML editors
- Programmatic filtering if needed
- Clear distinction between original and discovered URLs

### Usage

1. Review the file to verify discovered URLs are legitimate
2. Submit to Google Search Console: <https://search.google.com/search-console>
3. Submit to Bing Webmaster Tools: <https://www.bing.com/webmasters>
4. Use as your new canonical sitemap for complete site coverage
5. Replace old sitemap after validation

---

## Data Relationships

### Cross-Report Joins

All reports can be joined using `URL` as the common key (except image and link reports):

```sql
-- Example: Join SEO report with Performance data
SELECT
  seo.URL,
  seo.Title,
  seo."Word Count",
  perf."Load Time (ms)",
  perf."Largest Contentful Paint (ms)"
FROM seo_report seo
JOIN performance_analysis perf ON seo.URL = perf.URL
WHERE perf."Load Time (ms)" > 3000;
```

### Report Dependencies

```
Original Sitemap URLs (input)
    ↓
URL Processing & Crawling
    ↓
Per-Page Reports:
    ├── seo_report.csv
    ├── performance_analysis.csv
    ├── accessibility_report.csv
    ├── content_quality.csv
    ├── seo_scores.csv
    ├── llm_readability_report.csv
    └── http_status_report.csv
    ↓
Aggregation Reports:
    ├── image_optimization.csv (from all pages' images)
    ├── link_analysis.csv (from all pages' links)
    ├── all_resources_report.csv (site-wide resource inventory)
    └── missing_sitemap_urls.csv (discovered - original)
    ↓
Output Reports:
    ├── wcag_report.md (formatted from accessibility data)
    └── v-sitemap.xml (original + discovered URLs)
```

---

## Data Types Reference

### Common Data Types

| Type | Format | Example | Validation |
|------|--------|---------|------------|
| String (URL) | RFC 3986 | `https://example.com/page` | Must be valid HTTP/HTTPS |
| Integer | Whole number | `42` | No decimals |
| Float | Decimal number | `85.5` | 1-2 decimal places typical |
| Boolean | Literal string | `true`, `false` | Not `1`/`0` or `yes`/`no` |
| ISO 8601 DateTime | UTC timestamp | `2025-12-07T10:30:45.123Z` | Always UTC (Z suffix) |
| String (Enum) | Predefined values | `"critical"`, `"internal"` | Case-sensitive |
| Percentage | Float 0-100 | `75.5` | Not 0.0-1.0 |
| Ratio | Float 0-1.0 | `0.45` | Not percentage |

### Null Handling

- **CSV Format**: Empty string `""` represents null
- **Boolean Fields**: Never null, always `true` or `false`
- **Numeric Fields**: Can be null (empty) if data unavailable
- **URL Fields**: Never null in key fields, may be null in derived fields

---

## Parsing Guidelines for AI Assistants

### CSV Parsing

1. **Encoding**: All files are UTF-8 encoded
2. **Line Endings**: Platform-specific (CRLF on Windows, LF on Unix)
3. **Delimiter**: Comma `,`
4. **Quote Character**: Double quote `"`
5. **Escape**: Double quote doubled `""`
6. **Header Row**: First row contains field names
7. **Empty Fields**: Represent null values

### Example CSV Parsing (Python)

```python
import csv

with open('seo_report.csv', 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        url = row['URL']
        title = row['Title'] or None  # Empty string → None
        word_count = int(row['Word Count']) if row['Word Count'] else 0
        has_social = row['Has Social Tags'] == 'true'
```

### Querying Best Practices

1. **Always validate URLs** before assuming they're accessible
2. **Handle null values** explicitly (empty strings in CSV)
3. **Use appropriate data types** (int for counts, float for scores)
4. **Join reports by URL** for comprehensive analysis
5. **Sort by relevant metrics** based on analysis goal
6. **Filter by thresholds** (e.g., LCP > 2500ms for slow pages)

### Common Analysis Queries

**Find slow pages with poor SEO:**

```
Filter: Load Time > 3000ms AND Overall SEO Score < 70
Reports: performance_analysis.csv + seo_scores.csv
```

**Find images missing alt text on high-traffic pages:**

```
Filter: Alt Text = "" AND Optimization Score < 50
Reports: image_optimization.csv
Join: With seo_report.csv to get page context
```

**Identify accessibility issues by severity:**

```
Filter: Critical Issues > 0
Reports: accessibility_report.csv
Sort: By Critical Issues DESC
```

**Find most-used external resources:**

```
Filter: Resource Type = "javascript" AND Domain ≠ Site Domain
Reports: all_resources_report.csv
Sort: By Total Count DESC
```

---

## Schema Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | Initial | All original reports |
| 1.1.0 | 2025-11 | Added `llm_readability_report.csv` |
| 1.2.0 | 2025-12 | Added `http_status_report.csv`, moved logs to results folder |

### Version Compatibility

Results cached with schema version 1.x.y are compatible with:

- Same MAJOR.MINOR version (1.x.y ↔ 1.x.z)
- **NOT compatible** with different MAJOR or MINOR versions

When schema changes:

- Tool automatically detects incompatibility
- Forces fresh analysis to regenerate reports
- Logged as warning with explanation

---

## Additional Resources

### Cache Files

The tool also generates cache files for debugging:

| Location | Content | Format |
|----------|---------|--------|
| `.cache/rendered/{hash}.html` | Puppeteer-rendered HTML | HTML |
| `.cache/rendered/{hash}.log` | Browser console output | Plain text |
| `.cache/served/{hash}.html` | Original served HTML | HTML |

**Hash**: MD5 hash of URL for consistent naming
**Console Log Format**: `[timestamp] [TYPE] message`

### Log Files

| File | Location | Content |
|------|----------|---------|
| `error.log` | Output directory | Error-level messages only |
| `combined.log` | Output directory | All log levels (debug, info, warn, error) |

---

## 14. Executive Summary (Markdown) (`executive_summary.md`)

**Purpose**: High-level overview report with key insights and recommendations
**Generated**: When `--generate-executive-summary` flag is used
**Format**: Markdown (human-readable)

### Structure

```markdown
# Executive Summary

**Site:** [domain]
**Generated:** [timestamp]
**Pages Analyzed:** [count]
**robots.txt Compliance:** [✅/⚠️] [Enabled/Disabled]
**Cache Staleness:** [✅/⚠️/ℹ️] [capability message]

## Overall Score: [score]/100 ([status])

## Overall Status
[Table with Performance, Accessibility, SEO, LLM status and scores]

## Performance
- Status, Average Load Time, LCP, FCP, CLS
- Trend information (if history enabled)

## Accessibility
- Status, Total Issues, Errors, Warnings, Notices
- Trend information (if history enabled)

## SEO
- Status, Average Score, Pages Analyzed
- Trend information (if history enabled)

## Content Quality
- Average Word Count, Headings, Low Content Pages
- Trend information (if history enabled)

## LLM Agent Suitability
- Status, Served Score, Rendered Score, llms.txt count
- Trend information (if history enabled)

## Key Findings
[Numbered list of critical findings with severity icons]

## Recommendations
[Numbered list of actionable recommendations with priority]

## Comparison with Previous Run
[If history enabled: improvements and regressions]
```

### Key Fields

- **Overall Score**: Headline score averaging Performance, Accessibility, SEO, and LLM Suitability scores (0-100)
- **Overall Status**: Pass/Warn/Fail for each category
- **Scores**: Numerical scores (0-100 where applicable)
- **Trends**: Percentage changes from previous run
- **Findings**: Critical issues requiring attention
- **Recommendations**: Prioritized action items
- **robots.txt Compliance**: Shows whether compliance mode was enabled during analysis
- **Cache Staleness**: Indicates whether the site provides HTTP Last-Modified headers for cache staleness detection
  - ✅ Site provides headers - cache staleness checking will work
  - ⚠️ Site does not provide headers - cache staleness checking will not work
  - ℹ️ Unable to determine (cache not available)

---

## 15. Executive Summary (JSON) (`executive_summary.json`)

**Purpose**: Machine-readable executive summary for automation
**Generated**: When `--generate-executive-summary` flag is used
**Format**: JSON

### JSON Structure

```json
{
  "generatedAt": "ISO 8601 timestamp",
  "site": "domain name",
  "overview": {
    "totalPages": 100,
    "analysisDate": "YYYY-MM-DD",
    "schemaVersion": "2.0.0",
    "robotsComplianceEnabled": true,
    "cacheStalenessNote": "string",
    "cacheStalenessCapable": true|false|null
  },
  "performance": {
    "status": "Excellent|Good|Fair|Poor",
    "score": 0-100,
    "averageLoadTime": "ms",
    "averageLCP": "ms",
    "averageFCP": "ms",
    "averageCLS": "0.0-1.0",
    "trend": { "loadTime": "%", "lcp": "%" }
  },
  "accessibility": {
    "status": "Excellent|Good|Fair|Critical",
    "score": 0-100,
    "totalIssues": "count",
    "errors": "count",
    "warnings": "count",
    "notices": "count",
    "averageIssuesPerPage": "float",
    "trend": { "totalIssues": "delta", "percentChange": "%" }
  },
  "seo": {
    "status": "Excellent|Very Good|Good|Fair|Needs Improvement",
    "score": 0-100,
    "pagesAnalyzed": "count",
    "trend": { "score": "delta", "percentChange": "%" }
  },
  "content": {
    "averageWordCount": "count",
    "averageHeadings": "float",
    "pagesWithLowContent": "count",
    "lowContentPercentage": "float",
    "trend": { "wordCount": "%" }
  },
  "llmSuitability": {
    "status": "Good|Fair|Needs Improvement",
    "servedScore": 0-100,
    "renderedScore": 0-100,
    "pagesWithLLMsTxt": "count",
    "trend": { "servedScore": "%", "renderedScore": "%" }
  },
  "keyFindings": [
    {
      "category": "Performance|Accessibility|SEO|Content|LLM",
      "severity": "Critical|High|Medium|Low",
      "finding": "description"
    }
  ],
  "recommendations": [
    {
      "category": "Performance|Accessibility|SEO|Content|LLM",
      "priority": "Critical|High|Medium|Low",
      "recommendation": "action item"
    }
  ],
  "comparison": {
    "improvements": ["list of improvements"],
    "regressions": ["list of regressions"],
    "urlCountChange": "delta"
  }
}
```

### Executive Summary JSON Field Descriptions

**Overview Section:**

- `totalPages`: Number of pages analyzed in this run
- `analysisDate`: Date when analysis was performed (YYYY-MM-DD format)
- `schemaVersion`: Data structure version for compatibility checking
- `robotsComplianceEnabled`: Boolean indicating if robots.txt compliance was enforced
  - `true`: Tool respected robots.txt directives (default, ethical mode)
  - `false`: Tool used force-scrape mode (bypassed robots.txt restrictions)
  - This field indicates whether the `--force-scrape` flag was used or `FORCE_SCRAPE=true` was set in .env
- `cacheStalenessNote`: Human-readable message about cache staleness capability
  - `"✅ Site provides HTTP Last-Modified header - cache staleness checking will work"`
  - `"⚠️ No Last-Modified header found in HTTP response - cache staleness checking will not work"`
  - `"ℹ️ Unable to determine (cache not available)"`
- `cacheStalenessCapable`: Boolean or null indicating if site supports cache staleness detection
  - `true`: Site provides HTTP Last-Modified headers, cache staleness checking will work
  - `false`: Site does not provide Last-Modified headers, cache staleness checking will not work
  - `null`: Unable to determine (cache files not available during report generation)

**robots.txt Compliance Context:**

When `robotsComplianceEnabled` is `true`, the tool:

- Fetched and parsed robots.txt before crawling
- Checked each URL against robots.txt rules
- Prompted user when URLs were blocked
- May have skipped some URLs due to robots.txt restrictions

When `robotsComplianceEnabled` is `false`, the tool:

- Bypassed all robots.txt restrictions
- Crawled all URLs regardless of robots.txt rules
- Used force-scrape mode (should only be used with explicit permission)

**Cache Staleness Capability Context:**

The `cacheStalenessNote` and `cacheStalenessCapable` fields indicate whether the analyzed site provides HTTP `Last-Modified` headers, which are required for automatic cache staleness detection.

Cache staleness checking works by:

1. Making HTTP HEAD requests to source URLs
2. Comparing the `Last-Modified` header from the source with the cache's `lastCrawled` timestamp
3. Automatically invalidating and deleting stale cache files when source content has changed

When `cacheStalenessCapable` is `true`:

- Site provides HTTP `Last-Modified` headers in responses
- Cache staleness checking will work automatically
- Stale cache files will be detected and refreshed on subsequent runs
- Users can rely on automatic cache invalidation

When `cacheStalenessCapable` is `false`:

- Site does not provide `Last-Modified` headers
- Cache staleness checking cannot determine freshness
- Cache is conservatively assumed to be fresh (to avoid unnecessary re-fetches)
- Users may need to manually clear cache with `--force-delete-cache` to ensure fresh data

When `cacheStalenessCapable` is `null`:

- Unable to determine capability (cache files not available during report generation)
- This typically occurs when running `--generate-executive-summary` without cache

**Implementation Details:**

The executive summary checks the first URL's cache file for the presence of a `Last-Modified` header in the cached `headers` object. This provides a representative sample of whether the site supports cache staleness detection. The check uses the same MD5 hash function as the caching system to locate cache files.

---

## 16. Interactive Dashboard (`dashboard.html`)

**Purpose**: Visual analytics dashboard with embedded charts
**Generated**: When `--generate-dashboard` flag is used
**Format**: Self-contained HTML with inline CSS, JavaScript, and embedded PNG charts

### Features

- **Overview Cards**: High-level status for each category
- **Embedded Charts**: Base64-encoded PNG images
  - Performance metrics bar chart
  - Accessibility issues pie chart
  - SEO score distribution bar chart
  - Content metrics bar chart
  - LLM suitability comparison chart
  - Historical trend line charts (if history enabled)
- **Comparison Tables**: Changes between runs (if history enabled)
- **Pass/Fail Tables**: Color-coded status summaries

### Chart Data Sources

All charts are generated from `results.json` and rendered as PNG images using Chart.js, then embedded as base64 data URIs.

---

## 17. Historical Results (`history/results-<timestamp>.json`)

**Purpose**: Timestamped snapshots for comparative analysis and trend tracking
**Generated**: When `--enable-history` flag is used
**Format**: JSON
**Filename Pattern**: `results-YYYY-MM-DDTHH-mm-ss-sssZ.json`

### Historical Data Structure

```json
{
  "timestamp": "ISO 8601 timestamp",
  "schemaVersion": "2.0.0",
  "results": {
    "urls": [...],
    "performanceAnalysis": [...],
    "pa11y": [...],
    "seoScores": [...],
    "contentAnalysis": [...],
    "llmMetrics": [...],
    "internalLinks": [...],
    "imageAnalysis": [...]
  }
}
```

### Usage

- **Comparative Analysis**: Compare metrics between runs
- **Trend Analysis**: Track changes over time
- **Regression Detection**: Identify performance degradation
- **Improvement Tracking**: Measure optimization impact

### Access Pattern

Historical results are loaded chronologically and compared:

```javascript
// Load all historical results
const historicalResults = await loadHistoricalResults(outputDir);

// Get most recent for comparison
const previousResult = historicalResults[historicalResults.length - 1];

// Compare with current
const comparison = compareResults(previousResult.results, currentResults);
```

---

## Configuration Files

### Threshold Configuration (`custom-thresholds.json`)

**Purpose**: Custom pass/fail criteria for all metrics
**Format**: JSON
**Location**: User-specified via `--thresholds` flag

### Structure

```json
{
  "performance": {
    "loadTime": { "pass": 3000, "warn": 5000 },
    "lcp": { "pass": 2500, "warn": 4000 },
    "fcp": { "pass": 1800, "warn": 3000 },
    "cls": { "pass": 0.1, "warn": 0.25 },
    "tti": { "pass": 3800, "warn": 7300 }
  },
  "accessibility": {
    "maxErrors": { "pass": 0, "warn": 5 },
    "maxWarnings": { "pass": 10, "warn": 30 },
    "maxTotalIssues": { "pass": 20, "warn": 50 }
  },
  "seo": {
    "minScore": { "pass": 80, "warn": 60 },
    "minTitleLength": { "pass": 30, "warn": 20 },
    "maxTitleLength": { "pass": 60, "warn": 70 },
    "minMetaDescLength": { "pass": 70, "warn": 50 },
    "maxMetaDescLength": { "pass": 155, "warn": 170 }
  },
  "content": {
    "minWordCount": { "pass": 300, "warn": 150 },
    "minHeadings": { "pass": 3, "warn": 1 }
  },
  "llm": {
    "minServedScore": { "pass": 70, "warn": 50 },
    "minRenderedScore": { "pass": 60, "warn": 40 }
  }
}
```

### Validation Rules

- All values must be numbers
- For performance metrics: `warn >= pass` (lower is better)
- For scores: `warn <= pass` (higher is better)
- CLS must be between 0 and 1

---

## Document Metadata

- **Last Updated**: 2026-01-01
- **Schema Version**: 2.0.0
- **Tool Version**: Web Audit Suite v2.0.0
- **Document Purpose**: AI assistant reference for programmatic report parsing
- **Audience**: AI assistants, automated analysis tools, integration developers

### Change Log

**v2.0.0** (2026-01-01):

- Added Executive Summary reports (Markdown and JSON)
- Added Interactive Dashboard (HTML with charts)
- Added Historical Results tracking
- Added Threshold Configuration schema
- Updated report count from 13 to 15+
- Added enhanced reports section
